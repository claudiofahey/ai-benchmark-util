{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.4'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .config('spark.driver.memory', '1000g')\n",
    "         .config('hive.exec.orc.default.stripe.size', 1024*1024*1024)\n",
    "         .getOrCreate()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/isilon1/data/mortgage/perf/Performance_*.txt\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/mnt/isilon1/data/mortgage'\n",
    "perf_file = os.path.join(data_dir, 'perf/Performance_*.txt')\n",
    "# perf_file = os.path.join(data_dir, 'perf/Performance_2016Q1.txt')\n",
    "print(perf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = [\n",
    "    (\"loan_id\", \"bigint\"),\n",
    "    (\"monthly_reporting_period\", \"date\"),\n",
    "    (\"servicer\", \"string\"),\n",
    "    (\"interest_rate\", \"double\"),\n",
    "    (\"current_actual_upb\", \"double\"),\n",
    "    (\"loan_age\", \"double\"),\n",
    "    (\"remaining_months_to_legal_maturity\", \"double\"),\n",
    "    (\"adj_remaining_months_to_maturity\", \"double\"),\n",
    "    (\"maturity_date\", \"string\"),\n",
    "    (\"msa\", \"double\"),\n",
    "    (\"current_loan_delinquency_status\", \"int\"),\n",
    "    (\"mod_flag\", \"string\"),\n",
    "    (\"zero_balance_code\", \"string\"),\n",
    "    (\"zero_balance_effective_date\", \"date\"),\n",
    "    (\"last_paid_installment_date\", \"date\"),\n",
    "    (\"foreclosed_after\", \"date\"),\n",
    "    (\"disposition_date\", \"date\"),\n",
    "    (\"foreclosure_costs\", \"double\"),\n",
    "    (\"prop_preservation_and_repair_costs\", \"double\"),\n",
    "    (\"asset_recovery_costs\", \"double\"),\n",
    "    (\"misc_holding_expenses\", \"double\"),\n",
    "    (\"holding_taxes\", \"double\"),\n",
    "    (\"net_sale_proceeds\", \"double\"),\n",
    "    (\"credit_enhancement_proceeds\", \"double\"),\n",
    "    (\"repurchase_make_whole_proceeds\", \"double\"),\n",
    "    (\"other_foreclosure_proceeds\", \"double\"),\n",
    "    (\"non_interest_bearing_upb\", \"double\"),\n",
    "    (\"principal_forgiveness_upb\", \"double\"),\n",
    "    (\"repurchase_make_whole_proceeds_flag\", \"string\"),\n",
    "    (\"foreclosure_principal_write_off_amount\", \"double\"),\n",
    "    (\"servicing_activity_indicator\", \"string\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = ','.join([' '.join(col) for col in dtypes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load(perf_file, format='csv', sep='|', schema=schema, header=False, dateFormat='MM/dd/yyyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_multiplier = 1.0\n",
    "if size_multiplier != 1.0:\n",
    "    print('Resampling')\n",
    "    df = df.sample(True, size_multiplier, seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "orc_dir = os.path.join(data_dir, 'from-spark3.orc')\n",
    "if os.path.exists(orc_dir): shutil.rmtree(orc_dir)\n",
    "(df.write\n",
    " .format('orc')\n",
    " .option('compression','snappy')\n",
    " .save(orc_dir)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
