{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obsolete - do not use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.handlers = []\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_path(\n",
    "    base_dir,\n",
    "    data_file_prefix,\n",
    "    size_multiplier,\n",
    "    partitions,\n",
    "    stripe_size_MiB,\n",
    "    compression,\n",
    "    file_format,\n",
    "    batch,\n",
    "    ):\n",
    "    \n",
    "    basename = '%s-%0.2fx-%dp-%dMiB-batch%d-%s.%s' % (\n",
    "        data_file_prefix, size_multiplier, partitions, stripe_size_MiB, batch, compression, file_format)\n",
    "    return os.path.join(base_dir, basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema_ddl():\n",
    "    dtypes = [\n",
    "        (\"loan_id\", \"bigint\"),\n",
    "        (\"monthly_reporting_period\", \"date\"),\n",
    "        (\"servicer\", \"string\"),\n",
    "        (\"interest_rate\", \"double\"),\n",
    "        (\"current_actual_upb\", \"double\"),\n",
    "        (\"loan_age\", \"double\"),\n",
    "        (\"remaining_months_to_legal_maturity\", \"double\"),\n",
    "        (\"adj_remaining_months_to_maturity\", \"double\"),\n",
    "        (\"maturity_date\", \"string\"),\n",
    "        (\"msa\", \"double\"),\n",
    "        (\"current_loan_delinquency_status\", \"int\"),\n",
    "        (\"mod_flag\", \"string\"),\n",
    "        (\"zero_balance_code\", \"string\"),\n",
    "        (\"zero_balance_effective_date\", \"date\"),\n",
    "        (\"last_paid_installment_date\", \"date\"),\n",
    "        (\"foreclosed_after\", \"date\"),\n",
    "        (\"disposition_date\", \"date\"),\n",
    "        (\"foreclosure_costs\", \"double\"),\n",
    "        (\"prop_preservation_and_repair_costs\", \"double\"),\n",
    "        (\"asset_recovery_costs\", \"double\"),\n",
    "        (\"misc_holding_expenses\", \"double\"),\n",
    "        (\"holding_taxes\", \"double\"),\n",
    "        (\"net_sale_proceeds\", \"double\"),\n",
    "        (\"credit_enhancement_proceeds\", \"double\"),\n",
    "        (\"repurchase_make_whole_proceeds\", \"double\"),\n",
    "        (\"other_foreclosure_proceeds\", \"double\"),\n",
    "        (\"non_interest_bearing_upb\", \"double\"),\n",
    "        (\"principal_forgiveness_upb\", \"double\"),\n",
    "        (\"repurchase_make_whole_proceeds_flag\", \"string\"),\n",
    "        (\"foreclosure_principal_write_off_amount\", \"double\"),\n",
    "        (\"servicing_activity_indicator\", \"string\")\n",
    "    ]\n",
    "    schema = ','.join([' '.join(col) for col in dtypes])\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mortgage_dataframe(\n",
    "    base_dir='/mnt/isilon1/data/mortgage',\n",
    "    input_file='perf/Performance_*.txt',\n",
    "    size_multiplier=1.0,\n",
    "    partitions=48,\n",
    "    stripe_size_MiB=64,\n",
    "    ):\n",
    "    \n",
    "    spark = (SparkSession\n",
    "         .builder\n",
    "         .config('spark.driver.memory', '1000g')\n",
    "         .config('hive.exec.orc.default.stripe.size', stripe_size_MiB*1024*1024)\n",
    "         .getOrCreate()\n",
    "         )\n",
    "    input_path = os.path.join(base_dir, input_file)\n",
    "    schema = get_schema_ddl()\n",
    "    df = spark.read.load(input_path, format='csv', sep='|', schema=schema, header=False, dateFormat='MM/dd/yyyy')\n",
    "    if size_multiplier != 1.0:\n",
    "        df = df.sample(True, size_multiplier, seed=7)\n",
    "    if partitions:\n",
    "        df = df.repartition(partitions)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_mortgage_dataframe(\n",
    "    df,\n",
    "    base_dir='/mnt/isilon1/data/mortgage',\n",
    "    data_file_prefix='perf-from-spark',\n",
    "    size_multiplier=1.0,\n",
    "    partitions=48,\n",
    "    stripe_size_MiB=64,\n",
    "    compression='snappy',\n",
    "    file_format='orc',\n",
    "    batch=0,\n",
    "    ):\n",
    "    \n",
    "    output_path = get_data_path(base_dir, data_file_prefix, size_multiplier, partitions, stripe_size_MiB, compression, file_format, batch)\n",
    "    logging.info('write_mortgage_dataframe: output_path=%s' % output_path)\n",
    "#     if size_multiplier != 1.0:\n",
    "#         df = df.sample(True, size_multiplier, seed=7+batch)\n",
    "    if os.path.exists(output_path): shutil.rmtree(output_path)\n",
    "    (df.write\n",
    "     .format(file_format)\n",
    "     .option('compression',compression)\n",
    "     .save(output_path))\n",
    "    logging.info('write_mortgage_dataframe: done.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = 48\n",
    "stripe_size_MiB = 2048\n",
    "size_multiplier = 3.0\n",
    "df = get_mortgage_dataframe(\n",
    "        size_multiplier=size_multiplier,\n",
    "        partitions=partitions,\n",
    "        stripe_size_MiB=stripe_size_MiB,\n",
    "        )\n",
    "df = df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for compression in ['snappy']:\n",
    "    for file_format in ['orc']:\n",
    "        for batch in range(100):\n",
    "            write_mortgage_dataframe(\n",
    "                df,\n",
    "                size_multiplier=size_multiplier,\n",
    "                partitions=partitions,\n",
    "                stripe_size_MiB=stripe_size_MiB,\n",
    "                compression=compression,\n",
    "                file_format=file_format,\n",
    "                batch=batch,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
