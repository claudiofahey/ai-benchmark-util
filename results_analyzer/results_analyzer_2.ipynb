{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install p3_data openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import json\n",
    "from io import StringIO\n",
    "import importlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p3_data\n",
    "importlib.reload(p3_data)\n",
    "from p3_data import (glob_file_list , load_json_from_file, merge_dicts, plot_groups, \n",
    "    get_varying_column_names, filter_dataframe, take_varying_columns,\n",
    "    load_json_records_as_dataframe, flatten_multiindex_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Load and Clean Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load result files from P3 Test Driver\n",
    "src_files = []\n",
    "src_files += ['../data/p3_test_driver/results/*.json.bz2']\n",
    "raw_df = load_json_records_as_dataframe(src=src_files, ignore_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_images_per_sec(output):\n",
    "    \"\"\"Search for last occurance of: total images/sec: 8169.88\"\"\"\n",
    "    try:\n",
    "        for m in re.finditer('^total images/sec: ([.0-9]+)$', output, flags=re.MULTILINE):\n",
    "            pass\n",
    "        return float(m.groups()[0])\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_suffix_info_df = pd.DataFrame([\n",
    "    {'data_dir_suffix': '', 'mean_bytes_per_image': 147531475882/1281167},\n",
    "    {'data_dir_suffix': '-150x', 'mean_bytes_per_image': 147531475882/1281167},\n",
    "    {'data_dir_suffix': '-png2', 'mean_bytes_per_image': 1750011440471/1281167},\n",
    "]).set_index(['data_dir_suffix'])\n",
    "data_dir_suffix_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean raw results\n",
    "def clean_result(result):\n",
    "    try:\n",
    "        r = result.copy()\n",
    "        r['utc_begin'] = pd.to_datetime(r['utc_begin'], utc=True)\n",
    "        r['utc_end'] = pd.to_datetime(r['utc_end'], utc=True)\n",
    "        r['images_per_sec'] = parse_images_per_sec(r['output'])\n",
    "        r['images_per_sec_per_gpu'] = r['images_per_sec'] / r['np']\n",
    "        r['storage_type'] = 'isilon'\n",
    "        return pd.Series(r)\n",
    "    except Exception as e:\n",
    "        print('ERROR: %s: %s' % (r['test_uuid'], e))\n",
    "        # raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = clean_result(raw_df.iloc[-1])\n",
    "#pd.DataFrame(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = raw_df.apply(clean_result, axis=1)\n",
    "clean_df = clean_df.set_index('test_uuid', drop=False)\n",
    "clean_df = clean_df[clean_df.error==False]\n",
    "clean_df = clean_df.sort_values(['utc_begin'])\n",
    "clean_df['num_copies'] = clean_df['num_copies'].fillna(1.0)\n",
    "clean_df.image_format = clean_df.image_format.fillna('JPEG')\n",
    "clean_df = clean_df.join(data_dir_suffix_info_df, on=['data_dir_suffix'])\n",
    "clean_df['MB_per_sec'] = clean_df['images_per_sec'] * clean_df['mean_bytes_per_image'] * 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_other_results_df = pd.read_csv('other_benchmark_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean other raw results\n",
    "def clean_other_result(result):\n",
    "    try:\n",
    "        r = result.copy()        \n",
    "        r['images_per_sec_per_gpu'] = r['images_per_sec'] / r['np']\n",
    "        r['NVIDIA_TENSORFLOW_VERSION'] = str(r['NVIDIA_TENSORFLOW_VERSION'])\n",
    "        return pd.Series(r)\n",
    "    except Exception as e:\n",
    "        #print('ERROR: %s: %s' % (r['test_uuid'], e))\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_other_results_df = raw_other_results_df.apply(clean_other_result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([clean_df, clean_other_results_df], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show list of columns\n",
    "list(clean_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns that identify test parameters\n",
    "param_cols = [\n",
    " 'NVIDIA_TENSORFLOW_VERSION',\n",
    " 'batch_group_size',\n",
    " 'batch_size',\n",
    " 'cached',\n",
    " 'datasets_num_private_threads',\n",
    " 'datasets_prefetch_buffer_size',\n",
    " 'fp16',\n",
    " 'image_format',\n",
    " 'model',\n",
    " 'np',\n",
    " 'num_batches',\n",
    " 'num_hosts',\n",
    " 'num_inter_threads',\n",
    " 'num_intra_threads',\n",
    " 'tensorflow_benchmark_git_hash',\n",
    " 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns that are the output of the experiments\n",
    "output_cols = [\n",
    "    'utc_begin',    \n",
    "    'images_per_sec',\n",
    "    'images_per_sec_per_gpu',\n",
    "    'MB_per_sec',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = param_cols + output_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View most recent results\n",
    "clean_df[cols].tail(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "clean_df[cols].to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.groupby(['model']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First level of filtering\n",
    "filt_df = filter_dataframe(\n",
    "    clean_df,\n",
    "#     cached=False,\n",
    "    image_format='PNG',\n",
    "    num_batches=(1000,50000),\n",
    ")\n",
    "len(filt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "    storage_type='isilon',\n",
    "    NVIDIA_TENSORFLOW_VERSION='19.09',\n",
    "    model='vgg16',\n",
    "    np=48,\n",
    "    num_batches=(500,50000),\n",
    "    cached=False,\n",
    "    num_copies=150,\n",
    "    image_format='JPEG',\n",
    ")\n",
    "take_varying_columns(filt1_df[cols].sort_values(['MB_per_sec'], ascending=False)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt2_df = filter_dataframe(\n",
    "    combined_df,\n",
    "    storage_type='na',\n",
    "#     model='resnet50',\n",
    "#     np=48,\n",
    "#     num_batches=(500,50000),\n",
    "#     cached=False,\n",
    "#     num_copies=150,\n",
    ")\n",
    "len(filt2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt3_df = pd.concat([filt1_df, filt2_df])\n",
    "len(filt3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filt3_df.fillna(0).groupby([\n",
    "    'NVIDIA_TENSORFLOW_VERSION',\n",
    "    'fp16',\n",
    "    'model',\n",
    "    'np',\n",
    "    'storage_type',\n",
    "    'cached',\n",
    "    'datasets_num_private_threads',\n",
    "]).mean()[['images_per_sec_per_gpu']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.unstack([\n",
    "    'storage_type',\n",
    "    'cached',\n",
    "    'datasets_num_private_threads',\n",
    "    'NVIDIA_TENSORFLOW_VERSION',\n",
    "])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline = df[('images_per_sec_per_gpu','isilon',True,2)]\n",
    "baseline = df[('images_per_sec_per_gpu','na',False,0.0,'19.02')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.div(baseline, axis=0) - 1.0) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.loc['bb2fe0e7-eeb9-45e4-aeca-470922d32a64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View output for a specific test\n",
    "print(combined_df.loc['bb2fe0e7-eeb9-45e4-aeca-470922d32a64'].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"\"\"mpirun --n 48 -allow-run-as-root --host dgx2-1:16,dgx2-2:16,dgx2-3:16 --report-bindings -bind-to none -map-by slot -x LD_LIBRARY_PATH -x PATH -mca plm_rsh_agent ssh -mca plm_rsh_args \"-p 2222\" -mca pml ob1 -mca btl ^openib -mca btl_tcp_if_include enp53s0 -x NCCL_DEBUG=INFO -x NCCL_IB_HCA=mlx5 -x NCCL_IB_SL=4 -x NCCL_IB_GID_INDEX=3 -x NCCL_NET_GDR_READ=1 -x NCCL_SOCKET_IFNAME=^docker0,lo ./round_robin_mpi.py python -u /tensorflow-benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model=resnet50 --batch_size=256 --batch_group_size=10 --num_batches=1000 --nodistortions --num_gpus=1 --device=gpu --force_gpu_compatible=True --data_format=NCHW --use_fp16=True --use_tf_layers=True --data_name=imagenet --use_datasets=True --num_intra_threads=1 --num_inter_threads=40 --datasets_prefetch_buffer_size=40 --datasets_num_private_threads=4 --train_dir=/imagenet-scratch/train_dir/2019-10-24-14-53-59-resnet50 --sync_on_finish=True --summary_verbosity=1 --save_summaries_steps=100 --save_model_secs=600 --variable_update=horovod --horovod_device=gpu --data_dir=/mnt/isilon1/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon2/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon3/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon4/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon5/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon6/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon7/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon8/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon9/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon10/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon11/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon12/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon13/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon14/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon15/data/imagenet-scratch/tfrecords-150x --data_dir=/mnt/isilon16/data/imagenet-scratch/tfrecords-150x\"\"\"\n",
    "print(' \\\\ \\n'.join(output.split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Data to publish in WP (NGC 19.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First level of filtering\n",
    "filt_df = filter_dataframe(\n",
    "    combined_df,\n",
    ")\n",
    "len(filt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isilon\n",
    "filt_isi1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "    storage_type='isilon',\n",
    "    NVIDIA_TENSORFLOW_VERSION='19.09',\n",
    "    num_batches=(500,50000),\n",
    "    cached=False,\n",
    "    num_copies=150,\n",
    "    datasets_num_private_threads=4,\n",
    ")\n",
    "take_varying_columns(filt_isi1_df[cols]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux cache\n",
    "filt_cached1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "    storage_type='isilon',\n",
    "    NVIDIA_TENSORFLOW_VERSION='19.09',\n",
    "    num_batches=(500,50000),\n",
    "    cached=True,\n",
    "    datasets_num_private_threads=4,\n",
    ")\n",
    "take_varying_columns(filt_cached1_df[cols]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competitor 1\n",
    "filt_comp1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "    storage_type='na',\n",
    ")\n",
    "len(filt_comp1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt3_df = pd.concat([filt_isi1_df, filt_cached1_df, filt_comp1_df])\n",
    "len(filt3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cols = [\n",
    "    'NVIDIA_TENSORFLOW_VERSION',\n",
    "    'cached',\n",
    "    'datasets_num_private_threads',\n",
    "    'fp16',\n",
    "    'num_copies',\n",
    "    'storage_type',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = filt3_df.fillna(0).groupby(['model', 'np',] + agg_cols)\n",
    "df = g.agg({'images_per_sec_per_gpu': ['count','mean']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.stack()\n",
    "df.index.names = df.index.names[0:-1] + ['agg']\n",
    "df = df.unstack(agg_cols + ['agg'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('/home/jovyan/mnt/hgfs/Temp/tensorflow_benchmark_results_dgx2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = df[('images_per_sec_per_gpu','19.09',True,4,True,1.0,'isilon','mean')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.div(baseline, axis=0) - 1.0) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Comparison with other products (NGC 19.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First level of filtering\n",
    "filt_df = filter_dataframe(\n",
    "    combined_df,\n",
    ")\n",
    "len(filt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isilon\n",
    "filt_isi1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "    storage_type='isilon',\n",
    "    NVIDIA_TENSORFLOW_VERSION='19.02',\n",
    "    num_batches=(500,50000),\n",
    "    cached=False,\n",
    "    num_copies=150,\n",
    "    datasets_num_private_threads=4,\n",
    ")\n",
    "take_varying_columns(filt_isi1_df[cols]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux cache\n",
    "filt_cached1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "    storage_type='isilon',\n",
    "    NVIDIA_TENSORFLOW_VERSION='19.02',\n",
    "    num_batches=(500,50000),\n",
    "    cached=True,\n",
    "    datasets_num_private_threads=4,    \n",
    ")\n",
    "take_varying_columns(filt_cached1_df[cols]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competitor 1\n",
    "filt_comp1_df = filter_dataframe(\n",
    "    combined_df,\n",
    "    storage_type='na',\n",
    ")\n",
    "len(filt_comp1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt3_df = pd.concat([filt_isi1_df, filt_cached1_df, filt_comp1_df])\n",
    "len(filt3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cols = [\n",
    "    'NVIDIA_TENSORFLOW_VERSION',\n",
    "    'cached',\n",
    "    'datasets_num_private_threads',\n",
    "    'fp16',\n",
    "    'num_copies',\n",
    "    'storage_type',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = filt3_df.fillna(0).groupby(['model', 'np',] + agg_cols)\n",
    "df = g.agg({'images_per_sec_per_gpu': ['count','mean']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.stack()\n",
    "df.index.names = df.index.names[0:-1] + ['agg']\n",
    "df = df.unstack(agg_cols + ['agg'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline = df[('images_per_sec_per_gpu','isilon',True,2)]\n",
    "baseline = df[('images_per_sec_per_gpu','19.02',False,0.0,True,20.0,'na','mean')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.div(baseline, axis=0) - 1.0) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
