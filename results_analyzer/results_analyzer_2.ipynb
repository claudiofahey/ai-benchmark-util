{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install prerequisites, open a terminal in Jupyter and run the following commands:\n",
    "```\n",
    "git clone https://github.com/claudiofahey/p3_test_driver\n",
    "cd p3_test_driver\n",
    "pip install -e p3_data\n",
    "pip install openpyxl\n",
    "```\n",
    "Then restart the Python kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import json\n",
    "from io import StringIO\n",
    "import importlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p3_data\n",
    "importlib.reload(p3_data)\n",
    "from p3_data import (glob_file_list , load_json_from_file, merge_dicts, plot_groups, \n",
    "    get_varying_column_names, filter_dataframe, take_varying_columns,\n",
    "    load_json_records_as_dataframe, flatten_multiindex_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Load and Clean Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load result files from P3 Test Driver\n",
    "src_files = []\n",
    "src_files += ['../data/p3_test_driver/results/*.json.bz2']\n",
    "raw_df = load_json_records_as_dataframe(src=src_files, ignore_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_images_per_sec(output):\n",
    "    \"\"\"Search for last occurance of: total images/sec: 8169.88\"\"\"\n",
    "    try:\n",
    "        for m in re.finditer('^total images/sec: ([.0-9]+)$', output, flags=re.MULTILINE):\n",
    "            pass\n",
    "        return float(m.groups()[0])\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean raw results\n",
    "def clean_result(result):\n",
    "    try:\n",
    "        r = result.copy()\n",
    "        r['utc_begin'] = pd.to_datetime(r['utc_begin'], utc=True)\n",
    "        r['utc_end'] = pd.to_datetime(r['utc_end'], utc=True)\n",
    "        r['images_per_sec'] = parse_images_per_sec(r['output'])\n",
    "        r['images_per_sec_per_gpu'] = r['images_per_sec'] / r['np']\n",
    "        r['storage_type'] = 'isilon'\n",
    "        return pd.Series(r)\n",
    "    except Exception as e:\n",
    "        print('ERROR: %s: %s' % (r['test_uuid'], e))\n",
    "        # raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = clean_result(raw_df.iloc[-1])\n",
    "#pd.DataFrame(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = raw_df.apply(clean_result, axis=1)\n",
    "clean_df = clean_df.set_index('test_uuid', drop=False)\n",
    "clean_df = clean_df[clean_df.error==False]\n",
    "clean_df = clean_df.sort_values(['utc_begin'])\n",
    "clean_df['num_copies'] = clean_df['num_copies'].fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_other_results_df = pd.read_csv('other_benchmark_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean other raw results\n",
    "def clean_other_result(result):\n",
    "    try:\n",
    "        r = result.copy()        \n",
    "        r['images_per_sec_per_gpu'] = r['images_per_sec'] / r['np']\n",
    "        r['NVIDIA_TENSORFLOW_VERSION'] = str(r['NVIDIA_TENSORFLOW_VERSION'])\n",
    "        return pd.Series(r)\n",
    "    except Exception as e:\n",
    "        #print('ERROR: %s: %s' % (r['test_uuid'], e))\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_other_results_df = raw_other_results_df.apply(clean_other_result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([clean_df, clean_other_results_df], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show list of columns\n",
    "list(clean_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns that identify test parameters\n",
    "param_cols = [\n",
    " 'NVIDIA_TENSORFLOW_VERSION',\n",
    " 'batch_group_size',\n",
    " 'batch_size',\n",
    " 'cached',\n",
    " 'datasets_num_private_threads',\n",
    " 'datasets_prefetch_buffer_size',\n",
    " 'fp16',\n",
    " 'model',\n",
    " 'np',\n",
    " 'num_batches',\n",
    " 'num_inter_threads',\n",
    " 'num_intra_threads',\n",
    " 'tensorflow_benchmark_git_hash',\n",
    " 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns that are the output of the experiments\n",
    "output_cols = [\n",
    "    'utc_begin',    \n",
    "    'images_per_sec',\n",
    "    'images_per_sec_per_gpu',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = param_cols + output_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View most recent results\n",
    "clean_df[cols].tail(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "clean_df[cols].to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.groupby(['model']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First level of filtering\n",
    "filt_df = filter_dataframe(\n",
    "    clean_df,\n",
    "#     cached=False,\n",
    ")\n",
    "len(filt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "    storage_type='isilon',\n",
    "#     NVIDIA_TENSORFLOW_VERSION='19.09',\n",
    "#     model='resnet50',\n",
    "#     np=48,\n",
    "    num_batches=(500,50000),\n",
    "#     cached=False,\n",
    "#     num_copies=150,\n",
    ")\n",
    "take_varying_columns(filt1_df[cols]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt2_df = filter_dataframe(\n",
    "    combined_df,\n",
    "    storage_type='na',\n",
    "#     model='resnet50',\n",
    "#     np=48,\n",
    "#     num_batches=(500,50000),\n",
    "#     cached=False,\n",
    "#     num_copies=150,\n",
    ")\n",
    "len(filt2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt3_df = pd.concat([filt1_df, filt2_df])\n",
    "len(filt3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filt3_df.fillna(0).groupby([\n",
    "    'NVIDIA_TENSORFLOW_VERSION',\n",
    "    'fp16',\n",
    "    'model',\n",
    "    'np',\n",
    "    'storage_type',\n",
    "    'cached',\n",
    "    'datasets_num_private_threads',\n",
    "]).mean()[['images_per_sec_per_gpu']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.unstack([\n",
    "    'storage_type',\n",
    "    'cached',\n",
    "    'datasets_num_private_threads',\n",
    "    'NVIDIA_TENSORFLOW_VERSION',\n",
    "])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline = df[('images_per_sec_per_gpu','isilon',True,2)]\n",
    "baseline = df[('images_per_sec_per_gpu','na',False,0.0,'19.02')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.div(baseline, axis=0) - 1.0) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Data to publish in WP (NGC 19.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First level of filtering\n",
    "filt_df = filter_dataframe(\n",
    "    combined_df,\n",
    ")\n",
    "len(filt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isilon\n",
    "filt_isi1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "    storage_type='isilon',\n",
    "    NVIDIA_TENSORFLOW_VERSION='19.09',\n",
    "    num_batches=(500,50000),\n",
    "    cached=False,\n",
    "    num_copies=150,\n",
    "    datasets_num_private_threads=4,\n",
    ")\n",
    "take_varying_columns(filt_isi1_df[cols]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux cache\n",
    "filt_cached1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "    storage_type='isilon',\n",
    "    NVIDIA_TENSORFLOW_VERSION='19.09',\n",
    "    num_batches=(500,50000),\n",
    "    cached=True,\n",
    "    datasets_num_private_threads=4,\n",
    ")\n",
    "take_varying_columns(filt_cached1_df[cols]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competitor 1\n",
    "filt_comp1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "    storage_type='na',\n",
    ")\n",
    "len(filt_comp1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt3_df = pd.concat([filt_isi1_df, filt_cached1_df, filt_comp1_df])\n",
    "len(filt3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cols = [\n",
    "    'NVIDIA_TENSORFLOW_VERSION',\n",
    "    'cached',\n",
    "    'datasets_num_private_threads',\n",
    "    'fp16',\n",
    "    'num_copies',\n",
    "    'storage_type',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = filt3_df.fillna(0).groupby(['model', 'np',] + agg_cols)\n",
    "df = g.agg({'images_per_sec_per_gpu': ['count','mean']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.stack()\n",
    "df.index.names = df.index.names[0:-1] + ['agg']\n",
    "df = df.unstack(agg_cols + ['agg'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('/home/jovyan/mnt/hgfs/Temp/tensorflow_benchmark_results_dgx2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = df[('images_per_sec_per_gpu','19.09',True,4,True,1.0,'isilon','mean')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.div(baseline, axis=0) - 1.0) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Comparison with other products (NGC 19.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First level of filtering\n",
    "filt_df = filter_dataframe(\n",
    "    combined_df,\n",
    ")\n",
    "len(filt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isilon\n",
    "filt_isi1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "    storage_type='isilon',\n",
    "    NVIDIA_TENSORFLOW_VERSION='19.02',\n",
    "    num_batches=(500,50000),\n",
    "    cached=False,\n",
    "    num_copies=150,\n",
    "    datasets_num_private_threads=4,\n",
    ")\n",
    "take_varying_columns(filt_isi1_df[cols]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux cache\n",
    "filt_cached1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "    storage_type='isilon',\n",
    "    NVIDIA_TENSORFLOW_VERSION='19.02',\n",
    "    num_batches=(500,50000),\n",
    "    cached=True,\n",
    "    datasets_num_private_threads=4,    \n",
    ")\n",
    "take_varying_columns(filt_cached1_df[cols]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competitor 1\n",
    "filt_comp1_df = filter_dataframe(\n",
    "    combined_df,\n",
    "    storage_type='na',\n",
    ")\n",
    "len(filt_comp1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt3_df = pd.concat([filt_isi1_df, filt_cached1_df, filt_comp1_df])\n",
    "len(filt3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cols = [\n",
    "    'NVIDIA_TENSORFLOW_VERSION',\n",
    "    'cached',\n",
    "    'datasets_num_private_threads',\n",
    "    'fp16',\n",
    "    'num_copies',\n",
    "    'storage_type',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = filt3_df.fillna(0).groupby(['model', 'np',] + agg_cols)\n",
    "df = g.agg({'images_per_sec_per_gpu': ['count','mean']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.stack()\n",
    "df.index.names = df.index.names[0:-1] + ['agg']\n",
    "df = df.unstack(agg_cols + ['agg'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline = df[('images_per_sec_per_gpu','isilon',True,2)]\n",
    "baseline = df[('images_per_sec_per_gpu','19.02',False,0.0,True,20.0,'na','mean')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.div(baseline, axis=0) - 1.0) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
