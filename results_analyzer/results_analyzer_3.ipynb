{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install p3_data openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import json\n",
    "from io import StringIO\n",
    "import importlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p3_data\n",
    "from p3_data import (glob_file_list , load_json_from_file, merge_dicts, plot_groups, \n",
    "    get_varying_column_names, filter_dataframe, take_varying_columns,\n",
    "    load_json_records_as_dataframe, flatten_multiindex_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Load and Clean Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load result files from P3 Test Driver\n",
    "src_files = []\n",
    "src_files += ['../data/p3_test_driver/results/*.json.bz2']\n",
    "raw_df = load_json_records_as_dataframe(src=src_files, ignore_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_images_per_sec(output):\n",
    "    \"\"\"Search for last occurance of: total images/sec: 8169.88\"\"\"\n",
    "    try:\n",
    "        for m in re.finditer('^total images/sec: ([.0-9]+)$', output, flags=re.MULTILINE):\n",
    "            pass\n",
    "        return float(m.groups()[0])\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_suffix_info_df = pd.DataFrame([\n",
    "    {'data_dir_suffix': '', 'mean_bytes_per_image': 147531475882/1281167},\n",
    "    {'data_dir_suffix': '-150x', 'mean_bytes_per_image': 147531475882/1281167},\n",
    "    {'data_dir_suffix': '-13x', 'mean_bytes_per_image': 147531475882/1281167},\n",
    "    {'data_dir_suffix': '-png2', 'mean_bytes_per_image': 1750011440471/1281167},\n",
    "]).set_index(['data_dir_suffix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean raw results\n",
    "def clean_result(result):\n",
    "    try:\n",
    "        r = result.copy()\n",
    "        r['utc_begin'] = pd.to_datetime(r['utc_begin'], utc=True)\n",
    "        r['utc_end'] = pd.to_datetime(r['utc_end'], utc=True)\n",
    "        r['num_gpus'] = r['np']\n",
    "        r['images_per_sec'] = parse_images_per_sec(r['output'])\n",
    "        r['images_per_sec_per_gpu'] = r['images_per_sec'] / r['num_gpus']\n",
    "        r['image_format'] = 'JPEG'\n",
    "        return pd.Series(r)\n",
    "    except Exception as e:\n",
    "        print('ERROR: %s: %s' % (r['test_uuid'], e))\n",
    "        # raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = clean_result(raw_df.iloc[-1])\n",
    "#pd.DataFrame(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = raw_df.apply(clean_result, axis=1)\n",
    "clean_df = clean_df.set_index('test_uuid', drop=False)\n",
    "clean_df = clean_df[clean_df.error==False]\n",
    "clean_df = clean_df.sort_values(['utc_begin'])\n",
    "clean_df['num_copies'] = clean_df['num_copies'].fillna(1.0)\n",
    "clean_df.mpi = clean_df.mpi.fillna(True)\n",
    "clean_df.storage_type = clean_df.storage_type.fillna('isilon')\n",
    "clean_df.use_tf_layers = clean_df.use_tf_layers.fillna(True)\n",
    "clean_df.nvlink = clean_df.nvlink.fillna(True)\n",
    "clean_df = clean_df.join(data_dir_suffix_info_df, on=['data_dir_suffix'])\n",
    "clean_df['MB_per_sec'] = clean_df['images_per_sec'] * clean_df['mean_bytes_per_image'] * 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean other raw results\n",
    "def clean_other_result(result):\n",
    "    try:\n",
    "        r = result.copy()        \n",
    "        r['images_per_sec_per_gpu'] = r['images_per_sec'] / r['np']\n",
    "        r['NVIDIA_TENSORFLOW_VERSION'] = str(r['NVIDIA_TENSORFLOW_VERSION'])\n",
    "        return pd.Series(r)\n",
    "    except Exception as e:\n",
    "        #print('ERROR: %s: %s' % (r['test_uuid'], e))\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    raw_other_results_df = pd.read_csv('other_benchmark_results.csv')\n",
    "    clean_other_results_df = raw_other_results_df.apply(clean_other_result, axis=1)\n",
    "    combined_df = pd.concat([clean_df, clean_other_results_df], sort=False)\n",
    "else:\n",
    "    combined_df = clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show list of columns\n",
    "list(clean_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns that identify test parameters\n",
    "param_cols = [\n",
    " 'NVIDIA_TENSORFLOW_VERSION',\n",
    " 'TENSORFLOW_VERSION',\n",
    " 'batch_group_size',\n",
    " 'batch_size',\n",
    " 'cached',\n",
    " 'datasets_num_private_threads',\n",
    " 'datasets_prefetch_buffer_size',\n",
    " 'fp16',\n",
    " 'use_tf_layers',\n",
    " 'image_format',\n",
    " 'model',\n",
    " 'mpi',\n",
    " 'np',\n",
    " 'num_batches',\n",
    " 'num_gpus',\n",
    " 'num_hosts',\n",
    " 'num_inter_threads',\n",
    " 'num_intra_threads',\n",
    " 'nvlink',\n",
    " 'tensorflow_benchmark_git_hash',\n",
    " 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns that are the output of the experiments\n",
    "output_cols = [\n",
    "    'utc_begin',    \n",
    "    'images_per_sec',\n",
    "    'images_per_sec_per_gpu',\n",
    "    'MB_per_sec',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = param_cols + output_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View most recent results\n",
    "clean_df[cols].tail(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "clean_df[cols].to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.groupby(['model']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.groupby(['storage_type']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.groupby(['isilon_node_pool_name']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVLink vs. No NVLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First level of filtering\n",
    "filt_df = filter_dataframe(\n",
    "    clean_df,\n",
    "    #cached=True,\n",
    "    image_format='JPEG',\n",
    "    num_batches=(1000,50000),\n",
    ")\n",
    "len(filt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "    batch_size=192,\n",
    "    cached=True,\n",
    "    datasets_num_private_threads=4,\n",
    "#     image_format='JPEG',\n",
    "#     model='resnet50',\n",
    "#     np=2,\n",
    "    num_batches=(500,50000),\n",
    "    #num_copies=1,\n",
    "#     num_gpus=1,\n",
    "    num_inter_threads=40,\n",
    "    num_intra_threads=1,\n",
    "#     NVIDIA_TENSORFLOW_VERSION='19.09',\n",
    "#     storage_type='local',\n",
    "    use_tf_layers=True,\n",
    ")\n",
    "take_varying_columns(filt1_df[cols].sort_values(['MB_per_sec'], ascending=False)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt3_df = pd.concat([filt1_df])\n",
    "len(filt3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filt3_df.fillna(0).groupby([\n",
    "    #'NVIDIA_TENSORFLOW_VERSION',\n",
    "    #'fp16',\n",
    "    'model',\n",
    "    'num_gpus',\n",
    "#     'mpi',\n",
    "#     'storage_type',\n",
    "#     'cached',\n",
    "#     'use_tf_layers',\n",
    "    'nvlink',\n",
    "#     'datasets_num_private_threads',\n",
    "#     'num_inter_threads',\n",
    "#     'num_intra_threads',\n",
    "#     'batch_size',\n",
    "]).mean()[['images_per_sec_per_gpu']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.unstack([\n",
    "    'num_gpus',\n",
    "    #'datasets_num_private_threads',\n",
    "#     'batch_size',\n",
    "#     'NVIDIA_TENSORFLOW_VERSION',\n",
    "#     'cached',\n",
    "#     'storage_type',\n",
    "#     'use_tf_layers',\n",
    "    'nvlink',\n",
    "])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[('images_per_sec_per_gpu',2,False)] / df2[('images_per_sec_per_gpu',2,True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot.bar(figsize=(12,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isilon H400 vs. NVMe, no NVLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First level of filtering\n",
    "filt_df = filter_dataframe(\n",
    "    clean_df,\n",
    "    #cached=True,\n",
    "    image_format='JPEG',\n",
    "    num_batches=(1000,50000),\n",
    "    nvlink=False,\n",
    ")\n",
    "len(filt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt1_df = filter_dataframe(\n",
    "    filt_df,\n",
    "#     batch_size=192,\n",
    "    cached=False,\n",
    "#     datasets_num_private_threads=4,\n",
    "#     image_format='JPEG',\n",
    "#     model='resnet50',\n",
    "#     np=2,\n",
    "    num_batches=(500,50000),\n",
    "    #num_copies=1,\n",
    "#     num_gpus=1,\n",
    "#     num_inter_threads=40,\n",
    "#     num_intra_threads=1,\n",
    "#     NVIDIA_TENSORFLOW_VERSION='19.09',\n",
    "    storage_type='isilon',\n",
    "    isilon_node_pool_name='h400_30tb_3.2tb-ssd_64gb',\n",
    "#     use_tf_layers=True,\n",
    ")\n",
    "take_varying_columns(filt1_df[cols].sort_values(['MB_per_sec'], ascending=False)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt2_df = filter_dataframe(\n",
    "    filt_df,\n",
    "#     batch_size=192,\n",
    "    cached=True,\n",
    "#     datasets_num_private_threads=4,\n",
    "#     image_format='JPEG',\n",
    "#     model='resnet50',\n",
    "#     np=2,\n",
    "    num_batches=(500,50000),\n",
    "    #num_copies=1,\n",
    "#     num_gpus=1,\n",
    "#     num_inter_threads=40,\n",
    "#     num_intra_threads=1,\n",
    "#     NVIDIA_TENSORFLOW_VERSION='19.09',\n",
    "    storage_type='local',\n",
    "#     use_tf_layers=True,\n",
    ")\n",
    "take_varying_columns(filt1_df[cols].sort_values(['MB_per_sec'], ascending=False)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt3_df = pd.concat([filt1_df, filt2_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filt3_df.fillna(0).groupby([\n",
    "    #'NVIDIA_TENSORFLOW_VERSION',\n",
    "    #'fp16',\n",
    "    'model',\n",
    "    'num_gpus',\n",
    "#     'mpi',\n",
    "    'storage_type',\n",
    "#     'cached',\n",
    "#     'use_tf_layers',\n",
    "#     'nvlink',\n",
    "#     'datasets_num_private_threads',\n",
    "#     'num_inter_threads',\n",
    "#     'num_intra_threads',\n",
    "#     'batch_size',\n",
    "]).agg({'images_per_sec_per_gpu': ['mean','count']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filt3_df.fillna(0).groupby([\n",
    "    #'NVIDIA_TENSORFLOW_VERSION',\n",
    "    #'fp16',\n",
    "    'model',\n",
    "    'num_gpus',\n",
    "#     'mpi',\n",
    "    'storage_type',\n",
    "#     'cached',\n",
    "#     'use_tf_layers',\n",
    "#     'nvlink',\n",
    "#     'datasets_num_private_threads',\n",
    "#     'num_inter_threads',\n",
    "#     'num_intra_threads',\n",
    "#     'batch_size',\n",
    "]).agg({'images_per_sec_per_gpu': ['mean']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.unstack([\n",
    "#     'num_gpus',\n",
    "    #'datasets_num_private_threads',\n",
    "#     'batch_size',\n",
    "#     'NVIDIA_TENSORFLOW_VERSION',\n",
    "#     'cached',\n",
    "    'storage_type',\n",
    "#     'use_tf_layers',\n",
    "#     'nvlink',\n",
    "])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[('images_per_sec_per_gpu','mean','isilon')] / df2[('images_per_sec_per_gpu','mean','local')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot.bar(figsize=(12,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel('results.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
